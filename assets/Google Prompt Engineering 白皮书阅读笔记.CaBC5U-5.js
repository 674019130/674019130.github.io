import{_ as f}from"./ValaxyMain.vue_vue_type_style_index_0_lang.DfSvu0AI.js";import{f as k,a as b,u as P}from"./chunks/vue-router._WMYa8cX.js";import{s as x,bH as l,aW as r,v as n,t as v,H as t,bi as y,aK as E,aM as h}from"./framework.DDojlQDl.js";import"./app.i6-hyFKY.js";import"./chunks/dayjs.DPscOGnl.js";import"./chunks/vue-i18n.D5iU1Uln.js";import"./chunks/pinia.DkkyVvQY.js";import"./chunks/@vueuse/motion.B7tSKkoB.js";import"./chunks/nprogress.DgNGesC2.js";import"./YunComment.vue_vue_type_style_index_0_lang.lVt8y9cy.js";import"./index.C5okkQwF.js";import"./YunPageHeader.vue_vue_type_script_setup_true_lang.CUTuRIHR.js";import"./post.D5cvIXgt.js";const T=k("/posts/Google Prompt Engineering 白皮书阅读笔记",async a=>JSON.parse(`{"title":"Google Prompt Engineering 白皮书阅读笔记","description":"","frontmatter":{"title":"Google Prompt Engineering 白皮书阅读笔记","tags":["Prompt Engineering","LLM","AI","读书笔记"],"categories":["技术笔记","AI与大模型"],"toc":true,"top":6,"aside":false},"headers":[{"level":2,"title":"参数['temperature', 'top_p', 'top_k', 'max_tokens']","slug":"参数-temperature-top-p-top-k-max-tokens","link":"#参数-temperature-top-p-top-k-max-tokens","children":[{"level":3,"title":"temperature","slug":"temperature","link":"#temperature","children":[]},{"level":3,"title":"top_p","slug":"top-p","link":"#top-p","children":[]},{"level":3,"title":"top_k","slug":"top-k","link":"#top-k","children":[]},{"level":3,"title":"max_tokens","slug":"max-tokens","link":"#max-tokens","children":[]}]},{"level":2,"title":"提示词分类","slug":"提示词分类","link":"#提示词分类","children":[{"level":3,"title":"['Zero prompting', 'Few shot prompting']","slug":"zero-prompting-few-shot-prompting","link":"#zero-prompting-few-shot-prompting","children":[]},{"level":3,"title":"['System', 'Role, 'Contextual']","slug":"system-role-contextual","link":"#system-role-contextual","children":[]},{"level":3,"title":"['Step-back prompting']","slug":"step-back-prompting","link":"#step-back-prompting","children":[]},{"level":3,"title":"['CoT', 'Self consistency', 'ToT']","slug":"cot-self-consistency-tot","link":"#cot-self-consistency-tot","children":[]},{"level":3,"title":"['ReAct', 'APE']","slug":"react-ape","link":"#react-ape","children":[]}]},{"level":2,"title":"为什么 Prompt Engineering 是 Engineering？","slug":"为什么-prompt-engineering-是-engineering","link":"#为什么-prompt-engineering-是-engineering","children":[]}],"relativePath":"pages/posts/Google Prompt Engineering 白皮书阅读笔记.md","lastUpdated":1747386466000}`),{lazy:(a,s)=>a.name===s.name}),H={__name:"Google Prompt Engineering 白皮书阅读笔记",setup(a,{expose:s}){var u;const{data:p}=T(),g=P(),m=b(),i=Object.assign(m.meta.frontmatter||{},((u=p.value)==null?void 0:u.frontmatter)||{});return m.meta.frontmatter=i,g.currentRoute.value.data=p.value,h("valaxy:frontmatter",i),globalThis.$frontmatter=i,s({frontmatter:{title:"Google Prompt Engineering 白皮书阅读笔记",tags:["Prompt Engineering","LLM","AI","读书笔记"],categories:["技术笔记","AI与大模型"],toc:!0,top:6,aside:!1}}),(o,e)=>{const d=f;return E(),x(d,{frontmatter:y(i)},{"main-content-md":l(()=>[e[0]||(e[0]=n("blockquote",null,[n("p",null,"You don’t need to be a data scientist or a machine learning engineer – everyone can write a prompt.")],-1)),e[1]||(e[1]=n("figure",null,[n("img",{src:"https://s2.loli.net/2025/04/16/zEiAw6lyxd3DpRK.png",alt:"CleanShot 2025-04-16 at 12.47.13@2x.png",loading:"lazy",decoding:"async"})],-1)),v(" more "),e[2]||(e[2]=n("h1",{id:"google-prompt-engineering-白皮书阅读笔记",tabindex:"-1"},[t("Google Prompt Engineering 白皮书阅读笔记 "),n("a",{class:"header-anchor",href:"#google-prompt-engineering-白皮书阅读笔记","aria-label":'Permalink to "Google Prompt Engineering 白皮书阅读笔记"'},"​")],-1)),e[3]||(e[3]=n("p",null,[t("Origin PDF link: "),n("a",{href:"https://drive.google.com/file/d/1AbaBYbEa_EbPelsT40-vj64L-2IwUJHy/view?pli=1",target:"_blank",rel:"noreferrer"},"https://drive.google.com/file/d/1AbaBYbEa_EbPelsT40-vj64L-2IwUJHy/view?pli=1")],-1)),e[4]||(e[4]=n("h2",{id:"参数-temperature-top-p-top-k-max-tokens",tabindex:"-1"},[t("参数"),n("code",null,"['temperature', 'top_p', 'top_k', 'max_tokens']"),t(),n("a",{class:"header-anchor",href:"#参数-temperature-top-p-top-k-max-tokens","aria-label":"Permalink to \"参数`['temperature', 'top_p', 'top_k', 'max_tokens']`\""},"​")],-1)),e[5]||(e[5]=n("h3",{id:"temperature",tabindex:"-1"},[n("code",null,"temperature"),t(),n("a",{class:"header-anchor",href:"#temperature","aria-label":'Permalink to "`temperature`"'},"​")],-1)),e[6]||(e[6]=n("p",null,"模型生成文本的随机性，一般来说，越大的值代表模型选取时随机性越大。 对于创作型任务，可以设置一个较大的值，使得模型生成更加多样化的文本。 对于类似数学计算，有确定答案的任务，可以设置一个较小的值，使得模型生成更加确定性的文本。",-1)),e[7]||(e[7]=n("p",null,[n("span",{class:"katex"},[n("span",{class:"katex-mathml"},[n("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[n("semantics",null,[n("mrow",null,[n("mn",null,"0")]),n("annotation",{encoding:"application/x-tex"},"0")])])]),n("span",{class:"katex-html","aria-hidden":"true"},[n("span",{class:"base"},[n("span",{class:"strut",style:{height:"0.6444em"}}),n("span",{class:"mord"},"0")])])]),t("记为 greedy decoding。")],-1)),e[8]||(e[8]=n("h3",{id:"top-p",tabindex:"-1"},[n("code",null,"top_p"),t(),n("a",{class:"header-anchor",href:"#top-p","aria-label":'Permalink to "`top_p`"'},"​")],-1)),e[9]||(e[9]=n("p",null,"选取概率最高的 token 的百分比。",-1)),e[10]||(e[10]=n("h3",{id:"top-k",tabindex:"-1"},[n("code",null,"top_k"),t(),n("a",{class:"header-anchor",href:"#top-k","aria-label":'Permalink to "`top_k`"'},"​")],-1)),e[11]||(e[11]=n("p",null,"选取概率最高的 k 个 token。",-1)),e[12]||(e[12]=n("h3",{id:"max-tokens",tabindex:"-1"},[n("code",null,"max_tokens"),t(),n("a",{class:"header-anchor",href:"#max-tokens","aria-label":'Permalink to "`max_tokens`"'},"​")],-1)),e[13]||(e[13]=n("p",null,"允许模型生成 token 的最大数量。",-1)),e[14]||(e[14]=n("p",null,[t("其中，"),n("code",null,"temperature"),t("、"),n("code",null,"top_p"),t(" 和 "),n("code",null,"top_k"),t(" 之间互相作用，通常不会同时设置三种参数。")],-1)),e[15]||(e[15]=n("hr",null,null,-1)),e[16]||(e[16]=n("h2",{id:"提示词分类",tabindex:"-1"},[t("提示词分类 "),n("a",{class:"header-anchor",href:"#提示词分类","aria-label":'Permalink to "提示词分类"'},"​")],-1)),e[17]||(e[17]=n("h3",{id:"zero-prompting-few-shot-prompting",tabindex:"-1"},[n("code",null,"['Zero prompting', 'Few shot prompting']"),t(),n("a",{class:"header-anchor",href:"#zero-prompting-few-shot-prompting","aria-label":"Permalink to \"`['Zero prompting', 'Few shot prompting']`\""},"​")],-1)),e[18]||(e[18]=n("p",null,"零样本提示： 不提供任何示例，直接给出提示词。",-1)),e[19]||(e[19]=n("p",null,"少样本提示： 提供少量示例，帮助模型理解任务，包括正例、反例，和 corner case。",-1)),e[20]||(e[20]=n("h3",{id:"system-role-contextual",tabindex:"-1"},[n("code",null,"['System', 'Role, 'Contextual']"),t(),n("a",{class:"header-anchor",href:"#system-role-contextual","aria-label":"Permalink to \"`['System', 'Role, 'Contextual']`\""},"​")],-1)),e[21]||(e[21]=n("p",null,"系统提示： 就像舞台剧的舞台一样。",-1)),e[22]||(e[22]=n("p",null,"角色提示： 告诉大模型舞台剧里应该扮演的角色。",-1)),e[23]||(e[23]=n("p",null,"上下文提示： 舞台剧的场景布置、具体细节。",-1)),e[24]||(e[24]=n("h3",{id:"step-back-prompting",tabindex:"-1"},[n("code",null,"['Step-back prompting']"),t(),n("a",{class:"header-anchor",href:"#step-back-prompting","aria-label":"Permalink to \"`['Step-back prompting']`\""},"​")],-1)),e[25]||(e[25]=n("p",null,[t("回退推理提示： 它提示 LLM 首先考虑与手头特定任务相关的一个更普遍的问题，然后将该普遍问题的答案输入到后续针对特定任务的提示中。"),n("strong",null,"这种「回退」允许 LLM 在尝试解决具体问题之前激活相关的背景知识和推理过程。")],-1)),e[26]||(e[26]=n("h3",{id:"cot-self-consistency-tot",tabindex:"-1"},[n("code",null,"['CoT', 'Self consistency', 'ToT']"),t(),n("a",{class:"header-anchor",href:"#cot-self-consistency-tot","aria-label":"Permalink to \"`['CoT', 'Self consistency', 'ToT']`\""},"​")],-1)),e[27]||(e[27]=n("h4",{id:"cot-chain-of-thought",tabindex:"-1"},[n("code",null,"CoT: Chain of Thought"),t(),n("a",{class:"header-anchor",href:"#cot-chain-of-thought","aria-label":'Permalink to "`CoT: Chain of Thought`"'},"​")],-1)),e[28]||(e[28]=n("p",null,'思维链提示： 通过在提示中添加"让我们一步一步思考"，引导模型展示其推理过程，而不是直接给出答案。这种方法特别适用于解决复杂问题，如数学题、逻辑推理或多步骤任务。',-1)),e[29]||(e[29]=n("p",null,[n("strong",null,"思维链提示和少样本提示结合，往往可以让大模型快速学习到当前问题的解题思路。")],-1)),e[30]||(e[30]=n("p",null,"例如：",-1)),e[31]||(e[31]=n("div",{class:"language- vp-adaptive-theme"},[n("button",{title:"Copy Code",class:"copy"}),n("span",{class:"lang"}),n("pre",{class:"shiki shiki-themes material-theme-lighter material-theme-darker vp-code"},[n("code",{"v-pre":""},[n("span",{class:"line"},[n("span",null,"问题：如果一本书的价格是15元，打八折后又减5元，最终价格是多少？")]),t(`
`),n("span",{class:"line"},[n("span",null,"让我们一步一步思考：")]),t(`
`),n("span",{class:"line"},[n("span",null,"1. 原价是15元")]),t(`
`),n("span",{class:"line"},[n("span",null,"2. 打八折后价格是15 × 0.8 = 12元")]),t(`
`),n("span",{class:"line"},[n("span",null,"3. 再减5元后价格是12 - 5 = 7元")]),t(`
`),n("span",{class:"line"},[n("span",null,"4. 所以最终价格是7元")])])]),n("button",{class:"collapse"})],-1)),e[32]||(e[32]=n("h4",{id:"self-consistency",tabindex:"-1"},[n("code",null,"Self consistency"),t(),n("a",{class:"header-anchor",href:"#self-consistency","aria-label":'Permalink to "`Self consistency`"'},"​")],-1)),e[33]||(e[33]=n("p",null,"自洽性提示： 通过让大模型生成多条不同的思维链路径，然后从中选择最一致或最常见的答案，提高推理准确性。这种技术结合了集成学习的思想，减少了单一推理路径可能带来的错误。",-1)),e[34]||(e[34]=n("p",null,"工作流程：",-1)),e[35]||(e[35]=n("ol",null,[n("li",null,"使用CoT生成多个不同的推理路径（通常通过调高temperature参数）"),n("li",null,"对每条路径得到的结果进行分析"),n("li",null,"选择出现频率最高的答案作为最终结果")],-1)),e[36]||(e[36]=n("p",null,"在多个答案中选择出现次数最多的答案作为最终结果，往往能让大模型在推理过程中更加准确。",-1)),e[37]||(e[37]=n("h4",{id:"tot-tree-of-thoughts",tabindex:"-1"},[n("code",null,"ToT: Tree of Thoughts"),t(),n("a",{class:"header-anchor",href:"#tot-tree-of-thoughts","aria-label":'Permalink to "`ToT: Tree of Thoughts`"'},"​")],-1)),e[38]||(e[38]=n("p",null,"思维树提示： 将思维链扩展为树状结构，模型在每一步都会探索多个可能的思考分支，然后评估这些分支的质量，选择最佳路径继续推理。这种方法适用于需要规划和探索不同可能性的复杂问题。",-1)),e[39]||(e[39]=n("p",null,"工作流程：",-1)),e[40]||(e[40]=n("ol",null,[n("li",null,"将问题分解为多个思考步骤"),n("li",null,'在每个步骤，生成多个可能的"思考"'),n("li",null,"评估每个思考的价值"),n("li",null,"基于评估结果选择最佳路径继续，或回溯到先前节点尝试不同路径"),n("li",null,"最终选择最优路径得出结论")],-1)),e[41]||(e[41]=n("blockquote",null,[n("p",null,"需要阅读其他笔记，这部分以后再补充。")],-1)),e[42]||(e[42]=n("hr",null,null,-1)),e[43]||(e[43]=n("h3",{id:"react-ape",tabindex:"-1"},[n("code",null,"['ReAct', 'APE']"),t(),n("a",{class:"header-anchor",href:"#react-ape","aria-label":"Permalink to \"`['ReAct', 'APE']`\""},"​")],-1)),e[44]||(e[44]=n("h4",{id:"react-reasoning-acting",tabindex:"-1"},[n("code",null,"ReAct: Reasoning + Acting"),t(),n("a",{class:"header-anchor",href:"#react-reasoning-acting","aria-label":'Permalink to "`ReAct: Reasoning + Acting`"'},"​")],-1)),e[45]||(e[45]=n("p",null,"推理与行动结合提示： 将思维链与行动交织在一起的框架，允许模型在思考的同时执行操作（如搜索信息、使用工具等），然后基于这些操作结果继续推理。特别适合需要外部信息或工具的复杂任务。",-1)),e[46]||(e[46]=n("p",null,"工作流程：",-1)),e[47]||(e[47]=n("ol",null,[n("li",null,[n("strong",null,"思考"),t("：分析当前情况和需要解决的问题")]),n("li",null,[n("strong",null,"行动"),t("：执行必要的操作（如搜索、计算等）")]),n("li",null,[n("strong",null,"观察"),t("：获取操作的结果")]),n("li",null,[n("strong",null,"继续思考"),t("：基于新信息更新推理")])],-1)),e[48]||(e[48]=n("h4",{id:"ape-automatic-prompt-engineering",tabindex:"-1"},[n("code",null,"APE: Automatic Prompt Engineering"),t(),n("a",{class:"header-anchor",href:"#ape-automatic-prompt-engineering","aria-label":'Permalink to "`APE: Automatic Prompt Engineering`"'},"​")],-1)),e[49]||(e[49]=n("p",null,"自动提示工程： 使用大模型自身来优化提示词的方法。通过让模型生成、评估和改进提示词，来找到对特定任务最有效的提示。这是一种元级别的应用，模型不仅用于解决问题，还用于找到最佳的问题表述方式。",-1)),e[50]||(e[50]=n("p",null,"工作流程：",-1)),e[51]||(e[51]=n("ol",null,[n("li",null,"初始提示生成：创建候选提示集合"),n("li",null,"提示评估：测试每个提示的效果"),n("li",null,"提示优化：根据评估结果改进提示"),n("li",null,"迭代：重复以上步骤，直到找到最优提示")],-1)),e[52]||(e[52]=n("p",null,"这种方法可以发现人类可能没有想到的有效提示策略，提高模型在特定任务上的表现。",-1)),e[53]||(e[53]=n("hr",null,null,-1)),e[54]||(e[54]=n("h2",{id:"为什么-prompt-engineering-是-engineering",tabindex:"-1"},[t("为什么 Prompt Engineering 是 "),n("strong",null,"Engineering"),t("？ "),n("a",{class:"header-anchor",href:"#为什么-prompt-engineering-是-engineering","aria-label":'Permalink to "为什么 Prompt Engineering 是 **Engineering**？"'},"​")],-1)),e[55]||(e[55]=n("p",null,[t("首先定义什么是 "),n("strong",null,"Engineering"),t("。")],-1)),e[56]||(e[56]=n("p",null,[n("strong",null,"Engineering"),t(" 是应用科学和数学原理来设计、构建和维护结构、机器和系统的实践。")],-1)),e[57]||(e[57]=n("p",null,[t("Prompt Engineering 同样需要经过设计、优化、迭代的过程。虽然大模型会出现幻觉，或者多次询问答案不一，但是经过统计学的分析，往往可以找到最优的提示策略。这个过程需要大量的实验和数据分析，所以同样是 "),n("strong",null,"Engineering"),t("。")],-1))]),"main-header":l(()=>[r(o.$slots,"main-header")]),"main-header-after":l(()=>[r(o.$slots,"main-header-after")]),"main-nav":l(()=>[r(o.$slots,"main-nav")]),"main-content-before":l(()=>[r(o.$slots,"main-content-before")]),"main-content":l(()=>[r(o.$slots,"main-content")]),"main-content-after":l(()=>[r(o.$slots,"main-content-after")]),"main-nav-before":l(()=>[r(o.$slots,"main-nav-before")]),"main-nav-after":l(()=>[r(o.$slots,"main-nav-after")]),comment:l(()=>[r(o.$slots,"comment")]),footer:l(()=>[r(o.$slots,"footer")]),aside:l(()=>[r(o.$slots,"aside")]),"aside-custom":l(()=>[r(o.$slots,"aside-custom")]),default:l(()=>[r(o.$slots,"default")]),_:3},8,["frontmatter"])}}};export{H as default,T as usePageData};
